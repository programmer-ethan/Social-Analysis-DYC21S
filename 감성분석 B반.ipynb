{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어분해 -> 단어벡터(i, like, you, hate, me, her) \n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "train=[\n",
    "    ('i like you','pos'),\n",
    "    ('i hate you','neg'),\n",
    "    ('you like me','pos'),\n",
    "    ('i like her','pos')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hate', 'her', 'i', 'like', 'me', 'you'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_words = set(word.lower() for sentence in train for word in word_tokenize(sentence[0]))\n",
    "all_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({'like': True,\n",
       "   'i': True,\n",
       "   'hate': False,\n",
       "   'you': True,\n",
       "   'me': False,\n",
       "   'her': False},\n",
       "  'pos'),\n",
       " ({'like': False,\n",
       "   'i': True,\n",
       "   'hate': True,\n",
       "   'you': True,\n",
       "   'me': False,\n",
       "   'her': False},\n",
       "  'neg'),\n",
       " ({'like': True,\n",
       "   'i': False,\n",
       "   'hate': False,\n",
       "   'you': True,\n",
       "   'me': True,\n",
       "   'her': False},\n",
       "  'pos'),\n",
       " ({'like': True,\n",
       "   'i': True,\n",
       "   'hate': False,\n",
       "   'you': False,\n",
       "   'me': False,\n",
       "   'her': True},\n",
       "  'pos')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = [({word: (word in word_tokenize(x[0])) for word in all_words}, x[1])\n",
    "                                                        for x in train]\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                     her = False             neg : pos    =      1.2 : 1.0\n",
      "                       i = True              neg : pos    =      1.2 : 1.0\n",
      "                      me = False             neg : pos    =      1.2 : 1.0\n",
      "                     you = True              neg : pos    =      1.2 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(t)\n",
    "classifier.show_most_informative_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'like': True,\n",
       " 'i': True,\n",
       " 'hate': False,\n",
       " 'you': False,\n",
       " 'me': False,\n",
       " 'her': False}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sentence='i like Mary'\n",
    "test_vector = {word: (word in word_tokenize(test_sentence.lower())) for word in all_words}\n",
    "test_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pos'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.classify(test_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한글\n",
    "from konlpy.tag import Okt\n",
    "pos_tagger=Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = [('메리가 좋아', 'pos'),\n",
    "         ('고양이도 좋아', 'pos'),\n",
    "         ('난 수업이 지루해', 'neg'),\n",
    "         ('메리는 이쁜 고양이야', 'pos'),\n",
    "         ('난 마치고 메리랑 놀거야', 'pos')\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'고양이도',\n",
       " '고양이야',\n",
       " '난',\n",
       " '놀거야',\n",
       " '마치고',\n",
       " '메리가',\n",
       " '메리는',\n",
       " '메리랑',\n",
       " '수업이',\n",
       " '이쁜',\n",
       " '좋아',\n",
       " '지루해'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_words = set(word.lower() for sentence in train for word in word_tokenize(sentence[0]))\n",
    "all_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({'메리랑': False,\n",
       "   '마치고': False,\n",
       "   '놀거야': False,\n",
       "   '좋아': True,\n",
       "   '고양이야': False,\n",
       "   '고양이도': False,\n",
       "   '메리가': True,\n",
       "   '지루해': False,\n",
       "   '메리는': False,\n",
       "   '난': False,\n",
       "   '수업이': False,\n",
       "   '이쁜': False},\n",
       "  'pos'),\n",
       " ({'메리랑': False,\n",
       "   '마치고': False,\n",
       "   '놀거야': False,\n",
       "   '좋아': True,\n",
       "   '고양이야': False,\n",
       "   '고양이도': True,\n",
       "   '메리가': False,\n",
       "   '지루해': False,\n",
       "   '메리는': False,\n",
       "   '난': False,\n",
       "   '수업이': False,\n",
       "   '이쁜': False},\n",
       "  'pos'),\n",
       " ({'메리랑': False,\n",
       "   '마치고': False,\n",
       "   '놀거야': False,\n",
       "   '좋아': False,\n",
       "   '고양이야': False,\n",
       "   '고양이도': False,\n",
       "   '메리가': False,\n",
       "   '지루해': True,\n",
       "   '메리는': False,\n",
       "   '난': True,\n",
       "   '수업이': True,\n",
       "   '이쁜': False},\n",
       "  'neg'),\n",
       " ({'메리랑': False,\n",
       "   '마치고': False,\n",
       "   '놀거야': False,\n",
       "   '좋아': False,\n",
       "   '고양이야': True,\n",
       "   '고양이도': False,\n",
       "   '메리가': False,\n",
       "   '지루해': False,\n",
       "   '메리는': True,\n",
       "   '난': False,\n",
       "   '수업이': False,\n",
       "   '이쁜': True},\n",
       "  'pos'),\n",
       " ({'메리랑': True,\n",
       "   '마치고': True,\n",
       "   '놀거야': True,\n",
       "   '좋아': False,\n",
       "   '고양이야': False,\n",
       "   '고양이도': False,\n",
       "   '메리가': False,\n",
       "   '지루해': False,\n",
       "   '메리는': False,\n",
       "   '난': True,\n",
       "   '수업이': False,\n",
       "   '이쁜': False},\n",
       "  'pos')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = [({word: (word in word_tokenize(x[0])) for word in all_words}, x[1])\n",
    "                                                        for x in train]\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                       난 = True              neg : pos    =      2.5 : 1.0\n",
      "                      좋아 = False             neg : pos    =      1.5 : 1.0\n",
      "                    고양이도 = False             neg : pos    =      1.1 : 1.0\n",
      "                    고양이야 = False             neg : pos    =      1.1 : 1.0\n",
      "                     놀거야 = False             neg : pos    =      1.1 : 1.0\n",
      "                     마치고 = False             neg : pos    =      1.1 : 1.0\n",
      "                     메리가 = False             neg : pos    =      1.1 : 1.0\n",
      "                     메리는 = False             neg : pos    =      1.1 : 1.0\n",
      "                     메리랑 = False             neg : pos    =      1.1 : 1.0\n",
      "                      이쁜 = False             neg : pos    =      1.1 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(t)\n",
    "classifier.show_most_informative_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'메리랑': False,\n",
       " '마치고': True,\n",
       " '놀거야': True,\n",
       " '좋아': False,\n",
       " '고양이야': False,\n",
       " '고양이도': False,\n",
       " '메리가': False,\n",
       " '지루해': False,\n",
       " '메리는': False,\n",
       " '난': True,\n",
       " '수업이': True,\n",
       " '이쁜': False}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sentence = '난 수업이 마치고 고양이랑 놀거야'\n",
    "test_vector = {word: (word in word_tokenize(test_sentence.lower())) for word in all_words}\n",
    "test_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'neg'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.classify(test_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(doc):\n",
    "    return [ t for t in pos_tagger.pos(doc, norm=True, stem=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([('메리', 'Noun'), ('가', 'Josa'), ('좋다', 'Adjective')], 'pos'),\n",
       " ([('고양이', 'Noun'), ('도', 'Josa'), ('좋다', 'Adjective')], 'pos'),\n",
       " ([('난', 'Noun'), ('수업', 'Noun'), ('이', 'Josa'), ('지루하다', 'Adjective')],\n",
       "  'neg'),\n",
       " ([('메리', 'Noun'),\n",
       "   ('는', 'Josa'),\n",
       "   ('이쁘다', 'Adjective'),\n",
       "   ('고양이', 'Noun'),\n",
       "   ('야', 'Josa')],\n",
       "  'pos'),\n",
       " ([('난', 'Noun'),\n",
       "   ('마치', 'Noun'),\n",
       "   ('고', 'Josa'),\n",
       "   ('메리', 'Noun'),\n",
       "   ('랑', 'Josa'),\n",
       "   ('놀다', 'Verb')],\n",
       "  'pos')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_docs = [(tokenize(row[0]), row[1]) for row in train]\n",
    "train_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('가', 'Josa'),\n",
       " ('고', 'Josa'),\n",
       " ('고양이', 'Noun'),\n",
       " ('난', 'Noun'),\n",
       " ('놀다', 'Verb'),\n",
       " ('는', 'Josa'),\n",
       " ('도', 'Josa'),\n",
       " ('랑', 'Josa'),\n",
       " ('마치', 'Noun'),\n",
       " ('메리', 'Noun'),\n",
       " ('수업', 'Noun'),\n",
       " ('야', 'Josa'),\n",
       " ('이', 'Josa'),\n",
       " ('이쁘다', 'Adjective'),\n",
       " ('좋다', 'Adjective'),\n",
       " ('지루하다', 'Adjective')}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = [t for d in train_docs for t in d[0]]\n",
    "set(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def term_exists(doc):\n",
    "    return {word: (word in set(doc)) for word in tokens}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({('메리', 'Noun'): True,\n",
       "   ('가', 'Josa'): True,\n",
       "   ('좋다', 'Adjective'): True,\n",
       "   ('고양이', 'Noun'): False,\n",
       "   ('도', 'Josa'): False,\n",
       "   ('난', 'Noun'): False,\n",
       "   ('수업', 'Noun'): False,\n",
       "   ('이', 'Josa'): False,\n",
       "   ('지루하다', 'Adjective'): False,\n",
       "   ('는', 'Josa'): False,\n",
       "   ('이쁘다', 'Adjective'): False,\n",
       "   ('야', 'Josa'): False,\n",
       "   ('마치', 'Noun'): False,\n",
       "   ('고', 'Josa'): False,\n",
       "   ('랑', 'Josa'): False,\n",
       "   ('놀다', 'Verb'): False},\n",
       "  'pos'),\n",
       " ({('메리', 'Noun'): False,\n",
       "   ('가', 'Josa'): False,\n",
       "   ('좋다', 'Adjective'): True,\n",
       "   ('고양이', 'Noun'): True,\n",
       "   ('도', 'Josa'): True,\n",
       "   ('난', 'Noun'): False,\n",
       "   ('수업', 'Noun'): False,\n",
       "   ('이', 'Josa'): False,\n",
       "   ('지루하다', 'Adjective'): False,\n",
       "   ('는', 'Josa'): False,\n",
       "   ('이쁘다', 'Adjective'): False,\n",
       "   ('야', 'Josa'): False,\n",
       "   ('마치', 'Noun'): False,\n",
       "   ('고', 'Josa'): False,\n",
       "   ('랑', 'Josa'): False,\n",
       "   ('놀다', 'Verb'): False},\n",
       "  'pos'),\n",
       " ({('메리', 'Noun'): False,\n",
       "   ('가', 'Josa'): False,\n",
       "   ('좋다', 'Adjective'): False,\n",
       "   ('고양이', 'Noun'): False,\n",
       "   ('도', 'Josa'): False,\n",
       "   ('난', 'Noun'): True,\n",
       "   ('수업', 'Noun'): True,\n",
       "   ('이', 'Josa'): True,\n",
       "   ('지루하다', 'Adjective'): True,\n",
       "   ('는', 'Josa'): False,\n",
       "   ('이쁘다', 'Adjective'): False,\n",
       "   ('야', 'Josa'): False,\n",
       "   ('마치', 'Noun'): False,\n",
       "   ('고', 'Josa'): False,\n",
       "   ('랑', 'Josa'): False,\n",
       "   ('놀다', 'Verb'): False},\n",
       "  'neg'),\n",
       " ({('메리', 'Noun'): True,\n",
       "   ('가', 'Josa'): False,\n",
       "   ('좋다', 'Adjective'): False,\n",
       "   ('고양이', 'Noun'): True,\n",
       "   ('도', 'Josa'): False,\n",
       "   ('난', 'Noun'): False,\n",
       "   ('수업', 'Noun'): False,\n",
       "   ('이', 'Josa'): False,\n",
       "   ('지루하다', 'Adjective'): False,\n",
       "   ('는', 'Josa'): True,\n",
       "   ('이쁘다', 'Adjective'): True,\n",
       "   ('야', 'Josa'): True,\n",
       "   ('마치', 'Noun'): False,\n",
       "   ('고', 'Josa'): False,\n",
       "   ('랑', 'Josa'): False,\n",
       "   ('놀다', 'Verb'): False},\n",
       "  'pos'),\n",
       " ({('메리', 'Noun'): True,\n",
       "   ('가', 'Josa'): False,\n",
       "   ('좋다', 'Adjective'): False,\n",
       "   ('고양이', 'Noun'): False,\n",
       "   ('도', 'Josa'): False,\n",
       "   ('난', 'Noun'): True,\n",
       "   ('수업', 'Noun'): False,\n",
       "   ('이', 'Josa'): False,\n",
       "   ('지루하다', 'Adjective'): False,\n",
       "   ('는', 'Josa'): False,\n",
       "   ('이쁘다', 'Adjective'): False,\n",
       "   ('야', 'Josa'): False,\n",
       "   ('마치', 'Noun'): True,\n",
       "   ('고', 'Josa'): True,\n",
       "   ('랑', 'Josa'): True,\n",
       "   ('놀다', 'Verb'): True},\n",
       "  'pos')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_xy = [(term_exists(d), c) for d,c in train_docs]\n",
    "train_xy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "           ('난', 'Noun') = True              neg : pos    =      2.5 : 1.0\n",
      "          ('메리', 'Noun') = False             neg : pos    =      2.5 : 1.0\n",
      "         ('고양이', 'Noun') = False             neg : pos    =      1.5 : 1.0\n",
      "     ('좋다', 'Adjective') = False             neg : pos    =      1.5 : 1.0\n",
      "           ('가', 'Josa') = False             neg : pos    =      1.1 : 1.0\n",
      "           ('고', 'Josa') = False             neg : pos    =      1.1 : 1.0\n",
      "          ('놀다', 'Verb') = False             neg : pos    =      1.1 : 1.0\n",
      "           ('는', 'Josa') = False             neg : pos    =      1.1 : 1.0\n",
      "           ('도', 'Josa') = False             neg : pos    =      1.1 : 1.0\n",
      "           ('랑', 'Josa') = False             neg : pos    =      1.1 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(train_xy)\n",
    "classifier.show_most_informative_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('난', 'Noun'),\n",
       " ('수업', 'Noun'),\n",
       " ('이', 'Josa'),\n",
       " ('마치', 'Noun'),\n",
       " ('면', 'Josa'),\n",
       " ('메리', 'Noun'),\n",
       " ('랑', 'Josa'),\n",
       " ('놀거야', 'Verb')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sentence = [(\"난 수업이 마치면 메리랑 놀거야\")]\n",
    "test_docs = pos_tagger.pos(test_sentence[0])\n",
    "test_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('난', 'Noun'): True,\n",
       " ('수업', 'Noun'): True,\n",
       " ('이', 'Josa'): True,\n",
       " ('마치', 'Noun'): True,\n",
       " ('면', 'Josa'): False,\n",
       " ('메리', 'Noun'): True,\n",
       " ('랑', 'Josa'): True,\n",
       " ('놀거야', 'Verb'): False}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sent_features = {word: (word in tokens) for word in test_docs}\n",
    "test_sent_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'neg'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.classify(test_sent_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
